{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kMALXaMv-MS"
   },
   "source": [
    "# Atlas Vector Search - LangGraph Integration - RAG Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [Build AI Agents with LangGraph](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langgraph/) page. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "This notebook takes you through how to use LangGraph to implement agentic RAG by using MongoDB Atlas as the vector database, LangChain to implement retrieval tools, and LangGraph to orchestrate the agent workflow.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/ai-integrations/langgraph.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxTXczeTghzU",
    "outputId": "ae3a81b2-cba6-42fc-f593-8646bff77b14",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade langgraph langgraph-checkpoint-mongodb langchain langchain_mongodb langchain-openai pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXLWCWEghuOX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<api-key>\"\n",
    "MONGODB_URI = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUf3jtFzO4-V"
   },
   "source": [
    "## Use Atlas as a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to your Atlas cluster\n",
    "client = MongoClient(MONGODB_URI)\n",
    "collection = client[\"sample_mflix\"][\"embedded_movies\"]\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", disallowed_special=())\n",
    "\n",
    "# Instantiate the vector store\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "   collection = collection,\n",
    "   embedding = embedding_model,\n",
    "   text_key = \"plot\",\n",
    "   embedding_key = \"plot_embedding\",\n",
    "   relevance_score_fn = \"dotProduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper method to create the vector search index\n",
    "vector_store.create_vector_search_index(\n",
    "   dimensions = 1536 # The dimensions of the vector embeddings to be indexed \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.index import create_fulltext_search_index\n",
    "import time\n",
    "\n",
    "# Use helper method to create the search index\n",
    "create_fulltext_search_index(\n",
    "   collection = collection,\n",
    "   field = \"title\",\n",
    "   index_name = \"search_index\"\n",
    ")\n",
    "\n",
    "# Wait for the index to build (this can take around a minute)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZfheX5FiIhU"
   },
   "source": [
    "## Define agent tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# Define a vector search tool\n",
    "@tool\n",
    "def vector_search(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "    \"\"\"\n",
    "    \n",
    "    retriever = vector_store.as_retriever(\n",
    "       search_type = \"similarity\",\n",
    "       search_kwargs = { \"k\": 5 } # Retrieve top 5 most similar documents\n",
    "    )\n",
    "\n",
    "    results = retriever.invoke(user_query)\n",
    "   \n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([f\"{doc.metadata['title']}: {doc.page_content}\" for doc in results])\n",
    "    return context\n",
    "\n",
    "# Test the tool\n",
    "test_results = vector_search.invoke(\"What are some movies that take place in the ocean?\")\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.retrievers.full_text_search import MongoDBAtlasFullTextSearchRetriever\n",
    "\n",
    "# Define a full-text search tool\n",
    "@tool\n",
    "def full_text_search(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve movie plot content based on the provided title.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the retriever\n",
    "    retriever = MongoDBAtlasFullTextSearchRetriever(\n",
    "       collection = collection,            # MongoDB Collection in Atlas\n",
    "       search_field = \"title\",             # Name of the field to search\n",
    "       search_index_name = \"search_index\", # Name of the search index\n",
    "       top_k = 1,                          # Number of top results to return       \n",
    "    ) \n",
    "    results = retriever.invoke(user_query)\n",
    "   \n",
    "    for doc in results:\n",
    "      if doc:\n",
    "          return doc.metadata[\"fullplot\"]\n",
    "      else:\n",
    "          return \"Movie not found\"\n",
    "  \n",
    "# Test the tool     \n",
    "full_text_search.invoke(\"What is the plot of Titanic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Create a chat prompt template for the agent, which includes a system prompt and a placeholder for `messages`\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI chatbot.\"\n",
    "            \" You are provided with tools to answer questions about movies.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    " \n",
    "tools = [\n",
    "    vector_search,\n",
    "    full_text_search\n",
    "]\n",
    "\n",
    "# Provide the tool names to the prompt\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "\n",
    "# Prepare the LLM by making the tools and prompt available to the model\n",
    "bind_tools = llm.bind_tools(tools)\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'name' of the tool that the LLM is calling.\n",
    "# Here, we expect the LLM to use the 'vector_search' tool.\n",
    "llm_with_tools.invoke([\"What are some movies that take place in the ocean?\"]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'name' of the tool that the LLM is calling.\n",
    "# Here, we expect the LLM to use the 'full_text_search' tool.\n",
    "llm_with_tools.invoke([\"What's the plot of Titanic?\"]).tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Define the graph state\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages`\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "# Add nodes using the `add_node` function\n",
    "# The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Define tools node\n",
    "def tools_node(state: GraphState) -> Dict[str, List]:\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content`` of the message is `observation`\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}\n",
    "\n",
    "# The `tools` node should run the `tools_node` function\n",
    "graph.add_node(\"tools\", tools_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Define a conditional edge\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Uses a conditional_edge to route to the tools node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Add a conditional edge from the `agent` node to the `tools` node\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()\n",
    "\n",
    "# Optionally, visualize the graph\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream outputs from the graph as they pass through its nodes\n",
    "def execute_graph(user_input: str) -> None:\n",
    "    # Add user input to the messages attribute of the graph state\n",
    "    # The role of the message should be \"user\" and content should be `user_input`\n",
    "    input = {\"messages\": [(\"user\", user_input)]}\n",
    "\n",
    "    # Pass input to the graph and stream the outputs\n",
    "    for output in app.stream(input):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "            \n",
    "    print(\"\\n---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some movies that take place in the ocean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What is the plot of Titanic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "\n",
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(client)\n",
    "\n",
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the `execute_graph` function to include the `thread_id` argument\n",
    "def execute_graph(thread_id: str, user_input: str) -> None:\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    input = {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                user_input,\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    for output in app.stream(input, config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "            \n",
    "    print(\"\\n---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph(\"1\", \"What's the plot of Titanic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph(\"1\", \"What movies are similar to the one I just asked about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
